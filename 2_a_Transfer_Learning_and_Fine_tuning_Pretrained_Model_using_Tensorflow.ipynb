{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gopalchettri/DeepLearning/blob/master/2_a_Transfer_Learning_and_Fine_tuning_Pretrained_Model_using_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Transfer Learning using Tensorflow by downloading the MobileNetV2 Model  from Tensorflow Hub**"
      ],
      "metadata": {
        "id": "Yx4zYM4Rz6Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Transfer-learning pipeline using a frozen MobileNetV2 feature extractor\n",
        "and a small custom classification head.\n",
        "\n",
        "The script:\n",
        "1. Imports libraries\n",
        "2. Loads the TF-Hub backbone\n",
        "3. Builds and compiles the model\n",
        "4. Prepares augmented image generators\n",
        "5. Trains, plots metrics, saves, reloads, and predicts\n",
        "\"\"\"\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 1. Library Imports\n",
        "# -----------------------------------------------------------\n",
        "import tensorflow as tf                      # Core deep-learning framework\n",
        "import tensorflow_hub as hub                 # Provides the TF-Hub model zoo\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt              # For metric visualisation\n",
        "import numpy as np                           # For numerical operations in prediction\n",
        "\n",
        "print(\"[INFO] All libraries imported ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 2. Load Pre-trained MobileNetV2 Feature Vector\n",
        "# -----------------------------------------------------------\n",
        "MODEL_URL   = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "INPUT_SHAPE = (224, 224, 3)                  # Expected (H, W, C) by backbone\n",
        "\n",
        "# hub.KerasLayer wraps a TF-Hub module so it behaves like a Keras layer.\n",
        "mobilenet_feature_extractor = hub.KerasLayer(\n",
        "    MODEL_URL,                               # Remote location of weights\n",
        "    input_shape=INPUT_SHAPE,                 # Fix input tensor size\n",
        "    trainable=False)                         # Freeze to keep backbone weights static\n",
        "\n",
        "print(\"[INFO] MobileNetV2 backbone loaded & frozen ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 3. Build the Classifier Head on top of the Frozen Backbone\n",
        "# -----------------------------------------------------------\n",
        "model = Sequential([\n",
        "    mobilenet_feature_extractor,             # (0) Pre-trained convolutional base\n",
        "    GlobalAveragePooling2D(),                # (1) Converts feature map → 1280-D vector\n",
        "    Dense(256, activation='relu'),           # (2) Fully-connected layer\n",
        "    Dense(128, activation='relu'),           # (3) Another FC layer\n",
        "    Dense(10,  activation='softmax')         # (4) Softmax → probabilities for 10 classes\n",
        "])\n",
        "\n",
        "print(\"[INFO] Model architecture created ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 4. Compile the Model\n",
        "# -----------------------------------------------------------\n",
        "model.compile(optimizer='adam',              # Adam optimiser (adaptive learning rate)\n",
        "              loss='sparse_categorical_crossentropy', # Integer labels → sparse\n",
        "              metrics=['accuracy'])          # Track classification accuracy\n",
        "\n",
        "print(\"[INFO] Model compiled; here is the summary:\")\n",
        "model.summary()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 5. Data Preparation with Augmentation\n",
        "# -----------------------------------------------------------\n",
        "DATA_DIR   = \"path/to/your/dataset\"          # Root folder with sub-dirs = class names\n",
        "BATCH_SIZE = 32                              # Number of images per mini-batch\n",
        "\n",
        "# ImageDataGenerator performs on-the-fly data augmentation & normalisation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,                          # Scale pixel values to [0, 1]\n",
        "    rotation_range=20,                       # Random rotates ±20°\n",
        "    width_shift_range=0.2,                   # Random horizontal shifts\n",
        "    height_shift_range=0.2,                  # Random vertical shifts\n",
        "    shear_range=0.2,                         # Shear transformations\n",
        "    zoom_range=0.2,                          # Random zooms\n",
        "    horizontal_flip=True,                    # Random horizontal flips\n",
        "    validation_split=0.20)                   # 20 % data reserved for validation\n",
        "\n",
        "# ----- Training subset generator -----\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=INPUT_SHAPE[:2],             # Resize images to 224×224\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse',                     # Integer labels expected by loss fn\n",
        "    subset='training')                       # Use training partition\n",
        "\n",
        "# ----- Validation subset generator -----\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    DATA_DIR,\n",
        "    target_size=INPUT_SHAPE[:2],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    subset='validation')                     # Use validation partition\n",
        "\n",
        "print(f\"[INFO] Data generators ready – \"\n",
        "      f\"{train_generator.samples} train images | \"\n",
        "      f\"{val_generator.samples} val images ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 6. Train the Model\n",
        "# -----------------------------------------------------------\n",
        "EPOCHS = 10\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch   = train_generator.samples // BATCH_SIZE,\n",
        "    validation_data   = val_generator,\n",
        "    validation_steps  = val_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS)\n",
        "\n",
        "print(\"[INFO] Training finished ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 7. Plot Accuracy & Loss Curves\n",
        "# -----------------------------------------------------------\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# --- Accuracy subplot ---\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'],     label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy per Epoch')\n",
        "plt.xlabel('Epoch');  plt.ylabel('Accuracy');  plt.legend()\n",
        "\n",
        "# --- Loss subplot ---\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'],     label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss per Epoch')\n",
        "plt.xlabel('Epoch');  plt.ylabel('Loss');  plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 8. Save the Trained Model\n",
        "# -----------------------------------------------------------\n",
        "MODEL_PATH = \"mobilenet_transfer_learning_model\"\n",
        "model.save(MODEL_PATH)\n",
        "print(f\"[INFO] Model saved to: {MODEL_PATH} ✔\")\n",
        "\n",
        "# -----------------------------------------------------------\n",
        "# 9. Reload the Model & Run a Demo Prediction\n",
        "# -----------------------------------------------------------\n",
        "loaded_model = tf.keras.models.load_model(\n",
        "    MODEL_PATH,\n",
        "    custom_objects={'KerasLayer': hub.KerasLayer})  # Needed to deserialize hub layer\n",
        "print(\"[INFO] Saved model re-loaded ✔\")\n",
        "\n",
        "# ----- Prepare / load a single image -----\n",
        "# Replace this random tensor with actual preprocessing of a real image\n",
        "sample_image = np.random.rand(1, *INPUT_SHAPE).astype(np.float32)\n",
        "\n",
        "# ----- Inference -----\n",
        "probabilities = loaded_model.predict(sample_image)  # Output shape: (1, 10)\n",
        "predicted_class_idx = np.argmax(probabilities, axis=1)[0]\n",
        "\n",
        "print(f\"[INFO] Predicted class index → {predicted_class_idx}\")\n"
      ],
      "metadata": {
        "id": "eUQ5UVfFGJch"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}